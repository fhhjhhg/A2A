{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fhhjhhg/A2A/blob/main/Copy_of_HYPIR_SD2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "    <img src=\"https://github.com/XPixelGroup/HYPIR/blob/main/assets/logo.png?raw=true\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "## HYPIR: Harnessing Diffusion-Yielded Score Priors for Image Restoration\n",
        "\n",
        "![visitors](https://visitor-badge.laobi.icu/badge?page_id=XPixelGroup/HYPIR) [![Try a demo on Replicate](https://replicate.com/0x3f3f3f3fun/hypir-sd2/badge)](https://replicate.com/0x3f3f3f3fun/hypir-sd2) [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/app-center/openxlab_app.svg)](TODO)\n",
        "\n",
        "Xinqi Lin<sup>1,2</sup>, [Fanghua Yu](https://github.com/Fanghua-Yu)<sup>1</sup>, Jinfan Hu<sup>1,2</sup>, [Zhiyuan You](https://zhiyuanyou.github.io/)<sup>1,3</sup>, Wu Shi<sup>1</sup>, [Jimmy S. Ren](https://www.jimmyren.com/)<sup>4,5</sup>, [Jinjin Gu](https://www.jasongt.com/)<sup>6,\\*</sup>, [Chao Dong](https://scholar.google.com.hk/citations?user=OSDCB0UAAAAJ)<sup>1,\\*</sup>\n",
        "\n",
        "\\*: Corresponding author"
      ],
      "metadata": {
        "id": "reTytqE2Jte8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VMG3oFhoqTAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-sgIFJW4qTRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import ai\n",
        "\n",
        "stream = ai.generate_text(\"Tell me a short story.\", stream=True)\n",
        "for text in stream:\n",
        "  print(text, end='')"
      ],
      "metadata": {
        "id": "RPzjNoKpq-UR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import ai\n",
        "\n",
        "stream = ai.generate_text(\"Tell me a short story.\", stream=True)\n",
        "for text in stream:\n",
        "  print(text, end='')"
      ],
      "metadata": {
        "id": "kjBFPpDkq_oM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import ai\n",
        "\n",
        "stream = ai.generate_text(\"Tell me a short story.\", stream=True)\n",
        "for text in stream:\n",
        "  print(text, end='')"
      ],
      "metadata": {
        "id": "3if2S-dfrAvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "worksheet = gc.open('Your spreadsheet name').sheet1\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "rows = worksheet.get_all_values()\n",
        "print(rows)\n",
        "\n",
        "# Convert to a DataFrame and render.\n",
        "import pandas as pd\n",
        "pd.DataFrame.from_records(rows)"
      ],
      "metadata": {
        "id": "_sTrLl38rC_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pypi.python.org/pypi/libarchive\n",
        "!apt-get -qq install -y libarchive-dev && pip install -U libarchive\n",
        "import libarchive"
      ],
      "metadata": {
        "id": "K28DijxhrD48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# List .txt files in the root.\n",
        "#\n",
        "# Search query reference:\n",
        "# https://developers.google.com/drive/v2/web/search-parameters\n",
        "listed = drive.ListFile({'q': \"title contains '.txt' and 'root' in parents\"}).GetList()\n",
        "for file in listed:\n",
        "  print('title {}, id {}'.format(file['title'], file['id']))"
      ],
      "metadata": {
        "id": "JDkxhvMprFP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# List .txt files in the root.\n",
        "#\n",
        "# Search query reference:\n",
        "# https://developers.google.com/drive/v2/web/search-parameters\n",
        "listed = drive.ListFile({'q': \"title contains '.txt' and 'root' in parents\"}).GetList()\n",
        "for file in listed:\n",
        "  print('title {}, id {}'.format(file['title'], file['id']))"
      ],
      "metadata": {
        "id": "bEzrXwtArGHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# List .txt files in the root.\n",
        "#\n",
        "# Search query reference:\n",
        "# https://developers.google.com/drive/v2/web/search-parameters\n",
        "listed = drive.ListFile({'q': \"title contains '.txt' and 'root' in parents\"}).GetList()\n",
        "for file in listed:\n",
        "  print('title {}, id {}'.format(file['title'], file['id']))"
      ],
      "metadata": {
        "id": "uqUvUezTrIZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6-57FpMOrPAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1cJbiF45qIFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lLAykE84qIW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8b1bec7"
      },
      "source": [
        "### Mount Google Drive\n",
        "\n",
        "Run the following cell to mount your Google Drive. This will prompt you to authenticate your Google account."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5387623",
        "outputId": "4a592eda-14f5-4886-b47f-bec406563794"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32850c98"
      },
      "source": [
        "Once your Drive is mounted, you can access your files from `/content/drive/My Drive/`. For example, to list the contents of your Drive, you can use:\n",
        "\n",
        "```bash\n",
        "!ls '/content/drive/My Drive/'\n",
        "```\n",
        "\n",
        "Or, if you know the path to your data, you can load it directly. For instance, to load a CSV file named `my_data.csv` located in the root of your 'My Drive' folder:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/My Drive/my_data.csv')\n",
        "print(df.head())\n",
        "```\n",
        "\n",
        "Please let me know the path to your data once your Drive is mounted, and I can help you load it."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Preparations\n",
        "\n",
        "1. Make sure you choose **GPU** as hardware. Free T4 GPU is good enough for running HYPIR-SD2 model.\n",
        "2. Clone the repository, install environment and download pre-trained weight."
      ],
      "metadata": {
        "id": "V0yseLp_UJhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf HYPIR\n",
        "!git clone https://github.com/XPixelGroup/HYPIR.git\n",
        "%cd HYPIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "L9QwLV4pT2oP",
        "outputId": "40f8681d-2899-46ad-a9ff-0a560fadbab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HYPIR'...\n",
            "remote: Enumerating objects: 69, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 69 (delta 16), reused 65 (delta 12), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (69/69), 4.87 MiB | 9.42 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n",
            "/content/HYPIR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n",
        "!wget https://huggingface.co/lxq007/HYPIR/resolve/main/HYPIR_sd2.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ctWygt7_VeGD",
        "outputId": "59228695-efdd-40fe-a7a6-b28946b03365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate==1.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: diffusers==0.32.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.32.2)\n",
            "Requirement already satisfied: gradio==5.21.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (5.21.0)\n",
            "Requirement already satisfied: lpips==0.1.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.1.4)\n",
            "Requirement already satisfied: open_clip_torch==2.31.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (2.31.0)\n",
            "Requirement already satisfied: openai==1.96.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.96.1)\n",
            "Requirement already satisfied: polars==1.24.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (1.24.0)\n",
            "Requirement already satisfied: tenacity==9.1.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (9.1.2)\n",
            "Requirement already satisfied: tensorboard==2.19.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.19.0)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision==0.21.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.21.0+cu124)\n",
            "Requirement already satisfied: vision-aided-loss==0.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (0.1.0)\n",
            "Requirement already satisfied: omegaconf==2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (2.3.0)\n",
            "Requirement already satisfied: python-dotenv==1.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (1.1.1)\n",
            "Requirement already satisfied: transformers==4.49.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (4.49.0)\n",
            "Requirement already satisfied: peft==0.14.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (0.14.0)\n",
            "Requirement already satisfied: einops==0.8.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (0.8.1)\n",
            "Requirement already satisfied: pydantic==2.10.6 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (2.10.6)\n",
            "Requirement already satisfied: opencv-python-headless==4.11.0.86 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (4.11.0.86)\n",
            "Requirement already satisfied: timm==1.0.15 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (1.0.15)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.4.0->-r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.4.0->-r requirements.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==1.4.0->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==1.4.0->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.4.0->-r requirements.txt (line 1)) (0.33.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.4.0->-r requirements.txt (line 1)) (0.5.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.32.2->-r requirements.txt (line 2)) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.32.2->-r requirements.txt (line 2)) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.32.2->-r requirements.txt (line 2)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.32.2->-r requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.32.2->-r requirements.txt (line 2)) (11.3.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.21.0->-r requirements.txt (line 3)) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.21.0->-r requirements.txt (line 3)) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio==5.21.0->-r requirements.txt (line 3)) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio==5.21.0->-r requirements.txt (line 3)) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.7.2 in /usr/local/lib/python3.11/dist-packages (from gradio==5.21.0->-r requirements.txt (line 3)) (1.7.2)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio==5.21.0->-r requirements.txt (line 3)) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio==5.21.0->-r requirements.txt (line 3)) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.21.0->-r requirements.txt (line 3)) (3.1.6)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.21.0->-r requirements.txt (line 3)) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.21.0->-r requirements.txt (line 3)) (3.11.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.21.0->-r requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio==5.21.0->-r requirements.txt (line 3)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio==5.21.0->-r requirements.txt (line 3)) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio==5.21.0->-r requirements.txt (line 3)) (0.12.4)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio==5.21.0->-r requirements.txt (line 3)) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.21.0->-r requirements.txt (line 3)) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.21.0->-r requirements.txt (line 3)) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.21.0->-r requirements.txt (line 3)) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio==5.21.0->-r requirements.txt (line 3)) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.21.0->-r requirements.txt (line 3)) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.21.0->-r requirements.txt (line 3)) (0.35.0)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from lpips==0.1.4->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.11/dist-packages (from lpips==0.1.4->-r requirements.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from open_clip_torch==2.31.0->-r requirements.txt (line 5)) (6.3.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.96.1->-r requirements.txt (line 6)) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.96.1->-r requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai==1.96.1->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.19.0->-r requirements.txt (line 9)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.19.0->-r requirements.txt (line 9)) (1.73.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.19.0->-r requirements.txt (line 9)) (3.8.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.19.0->-r requirements.txt (line 9)) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.19.0->-r requirements.txt (line 9)) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.19.0->-r requirements.txt (line 9)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.19.0->-r requirements.txt (line 9)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.19.0->-r requirements.txt (line 9)) (3.1.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (1.13.1)\n",
            "Requirement already satisfied: antialiased-cnns in /usr/local/lib/python3.11/dist-packages (from vision-aided-loss==0.1.0->-r requirements.txt (line 12)) (0.3)\n",
            "Requirement already satisfied: gdown==4.4.0 in /usr/local/lib/python3.11/dist-packages (from vision-aided-loss==0.1.0->-r requirements.txt (line 12)) (4.4.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf==2.3.0->-r requirements.txt (line 13)) (4.9.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0->-r requirements.txt (line 15)) (0.21.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.10.6->-r requirements.txt (line 18)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.10.6->-r requirements.txt (line 18)) (2.27.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown==4.4.0->vision-aided-loss==0.1.0->-r requirements.txt (line 12)) (4.13.4)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio==5.21.0->-r requirements.txt (line 3)) (15.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->-r requirements.txt (line 10)) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio==5.21.0->-r requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==5.21.0->-r requirements.txt (line 3)) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==5.21.0->-r requirements.txt (line 3)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio==5.21.0->-r requirements.txt (line 3)) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.4.0->-r requirements.txt (line 1)) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.21.0->-r requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.21.0->-r requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.21.0->-r requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.21.0->-r requirements.txt (line 3)) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.21.0->-r requirements.txt (line 3)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.21.0->-r requirements.txt (line 3)) (13.9.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->open_clip_torch==2.31.0->-r requirements.txt (line 5)) (0.2.13)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers==0.32.2->-r requirements.txt (line 2)) (3.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.32.2->-r requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.32.2->-r requirements.txt (line 2)) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.21.0->-r requirements.txt (line 3)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.21.0->-r requirements.txt (line 3)) (2.19.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown==4.4.0->vision-aided-loss==0.1.0->-r requirements.txt (line 12)) (2.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown==4.4.0->vision-aided-loss==0.1.0->-r requirements.txt (line 12)) (1.7.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==5.21.0->-r requirements.txt (line 3)) (0.1.2)\n",
            "--2025-07-27 16:18:12--  https://huggingface.co/lxq007/HYPIR/resolve/main/HYPIR_sd2.pth\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.202.121, 13.35.202.40, 13.35.202.34, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.202.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/bf/71/bf71afd85239d5d3a230b8d5e5c78a4e09a0043be21a673929d4224fdb7c03b1/d538a2cb925451fab1f75adfe715ac2b1c8bb12fa32a0851ba01be2347b354d6?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27HYPIR_sd2.pth%3B+filename%3D%22HYPIR_sd2.pth%22%3B&Expires=1753636692&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MzYzNjY5Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2JmLzcxL2JmNzFhZmQ4NTIzOWQ1ZDNhMjMwYjhkNWU1Yzc4YTRlMDlhMDA0M2JlMjFhNjczOTI5ZDQyMjRmZGI3YzAzYjEvZDUzOGEyY2I5MjU0NTFmYWIxZjc1YWRmZTcxNWFjMmIxYzhiYjEyZmEzMmEwODUxYmEwMWJlMjM0N2IzNTRkNj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=koMPkC4n3qDOnJ5wl1Xe80gXnRcoMfw30IDsCPMcOLclUhDMQIhh8WNdIcmjtEb9oRVBehUxi6kDkROZhcj89Z398L4EiLo02Fb7VslgXKbGr7f2s80g6drjeJgcQbwKo0YO7MBkmKsEZ2Zs2gHeityyPht4oWcsPmLhZ%7EGuAhKtWUxLZSS2xvitD9WF6VXQpfnwnR4MndHMrJRS9kk-8iDIv97nYsfYkJ9Nx6-Pn%7ExUpw5qwhANlOS-gasl4DBvTL5Mho14yfGZjp0ZDGrvFcaENNVhQepKbfLvlucWtXWZ-ePhwFir0p-HWJ8GsxGi6nW1G-X5sfxBHf92CWbYoQ__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-07-27 16:18:12--  https://cdn-lfs-us-1.hf.co/repos/bf/71/bf71afd85239d5d3a230b8d5e5c78a4e09a0043be21a673929d4224fdb7c03b1/d538a2cb925451fab1f75adfe715ac2b1c8bb12fa32a0851ba01be2347b354d6?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27HYPIR_sd2.pth%3B+filename%3D%22HYPIR_sd2.pth%22%3B&Expires=1753636692&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MzYzNjY5Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2JmLzcxL2JmNzFhZmQ4NTIzOWQ1ZDNhMjMwYjhkNWU1Yzc4YTRlMDlhMDA0M2JlMjFhNjczOTI5ZDQyMjRmZGI3YzAzYjEvZDUzOGEyY2I5MjU0NTFmYWIxZjc1YWRmZTcxNWFjMmIxYzhiYjEyZmEzMmEwODUxYmEwMWJlMjM0N2IzNTRkNj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=koMPkC4n3qDOnJ5wl1Xe80gXnRcoMfw30IDsCPMcOLclUhDMQIhh8WNdIcmjtEb9oRVBehUxi6kDkROZhcj89Z398L4EiLo02Fb7VslgXKbGr7f2s80g6drjeJgcQbwKo0YO7MBkmKsEZ2Zs2gHeityyPht4oWcsPmLhZ%7EGuAhKtWUxLZSS2xvitD9WF6VXQpfnwnR4MndHMrJRS9kk-8iDIv97nYsfYkJ9Nx6-Pn%7ExUpw5qwhANlOS-gasl4DBvTL5Mho14yfGZjp0ZDGrvFcaENNVhQepKbfLvlucWtXWZ-ePhwFir0p-HWJ8GsxGi6nW1G-X5sfxBHf92CWbYoQ__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 108.156.144.19, 108.156.144.84, 108.156.144.118, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|108.156.144.19|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1038090392 (990M) [binary/octet-stream]\n",
            "Saving to: â€˜HYPIR_sd2.pthâ€™\n",
            "\n",
            "HYPIR_sd2.pth       100%[===================>] 990.00M  84.0MB/s    in 8.3s    \n",
            "\n",
            "2025-07-27 16:18:21 (119 MB/s) - â€˜HYPIR_sd2.pthâ€™ saved [1038090392/1038090392]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Launch gradio app\n",
        "\n",
        "1. Run the next code block to launch gradio app. You'll need to **wait a few minutes** during the initial load, as the program downloads the Hugging Face pre-trained model.\n",
        "\n",
        "    During program execution, some information will pop up:\n",
        "\n",
        "    ```txt\n",
        "    Max size set to (2048, 2048), max pixels: 4194304\n",
        "    ...\n",
        "    Load model weights from HYPIR_sd2.pth\n",
        "    ...\n",
        "    Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
        "    * Running on public URL: https://58899f87fcc429eb66.gradio.live\n",
        "    ...\n",
        "    ```\n",
        "\n",
        "    You'll see a public URL, **click on it to access the Gradio page**. Hope you enjoy this model.\n",
        "2. â­If HYPIR is helpful for you, please help star this [repo](https://github.com/XPixelGroup/HYPIR). Thanks!ðŸ¤—"
      ],
      "metadata": {
        "id": "Qd8oG7GzYXcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "import gradio as gr\n",
        "import torchvision.transforms as transforms\n",
        "from accelerate.utils import set_seed\n",
        "from omegaconf import OmegaConf\n",
        "from PIL import Image\n",
        "\n",
        "from HYPIR.enhancer.sd2 import SD2Enhancer\n",
        "\n",
        "\n",
        "error_image = Image.open(os.path.join(\"assets\", \"gradio_error_img.png\"))\n",
        "\n",
        "# In this example, we set the max pixels to 2048x2048 to avoid processing images with excessively\n",
        "# high resolution. Set max_size to None to remove this constraint.\n",
        "\n",
        "max_size = (2048, 2048)\n",
        "# max_size = None\n",
        "if max_size is not None:\n",
        "    print(f\"Max size set to {max_size}, max pixels: {max_size[0] * max_size[1]}\")\n",
        "to_tensor = transforms.ToTensor()\n",
        "\n",
        "model = SD2Enhancer(\n",
        "    base_model_path=\"stabilityai/stable-diffusion-2-1-base\",\n",
        "    weight_path=\"HYPIR_sd2.pth\",\n",
        "    lora_modules=[\n",
        "        \"to_k\",\n",
        "        \"to_q\",\n",
        "        \"to_v\",\n",
        "        \"to_out.0\",\n",
        "        \"conv\",\n",
        "        \"conv1\",\n",
        "        \"conv2\",\n",
        "        \"conv_shortcut\",\n",
        "        \"conv_out\",\n",
        "        \"proj_in\",\n",
        "        \"proj_out\",\n",
        "        \"ff.net.2\",\n",
        "        \"ff.net.0.proj\",\n",
        "    ],\n",
        "    lora_rank=256,\n",
        "    model_t=200,\n",
        "    coeff_t=200,\n",
        "    device=\"cuda\",\n",
        ")\n",
        "model.init_models()\n",
        "\n",
        "\n",
        "def process(\n",
        "    image,\n",
        "    prompt,\n",
        "    upscale,\n",
        "    seed,\n",
        "    progress=gr.Progress(track_tqdm=True),\n",
        "):\n",
        "    if seed == -1:\n",
        "        seed = random.randint(0, 2**32 - 1)\n",
        "    set_seed(seed)\n",
        "    image = image.convert(\"RGB\")\n",
        "    # Check image size\n",
        "    if max_size is not None:\n",
        "        out_w, out_h = tuple(int(x * upscale) for x in image.size)\n",
        "        if out_w * out_h > max_size[0] * max_size[1]:\n",
        "            return error_image, (\n",
        "                \"Failed: The requested resolution exceeds the maximum pixel limit. \"\n",
        "                f\"Your requested resolution is ({out_h}, {out_w}). \"\n",
        "                f\"The maximum allowed pixel count is {max_size[0]} x {max_size[1]} \"\n",
        "                f\"= {max_size[0] * max_size[1]} :(\"\n",
        "            )\n",
        "\n",
        "    image_tensor = to_tensor(image).unsqueeze(0)\n",
        "    try:\n",
        "        pil_image = model.enhance(\n",
        "            lq=image_tensor,\n",
        "            prompt=prompt,\n",
        "            upscale=upscale,\n",
        "            return_type=\"pil\",\n",
        "        )[0]\n",
        "    except Exception as e:\n",
        "        return error_image, f\"Failed: {e} :(\"\n",
        "\n",
        "    return pil_image, f\"Success! :)\\nUsed prompt: {prompt}\"\n",
        "\n",
        "\n",
        "block = gr.Blocks().queue()\n",
        "with block:\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            image = gr.Image(type=\"pil\")\n",
        "            prompt = gr.Textbox(label=(\"Prompt\"))\n",
        "            upscale = gr.Slider(minimum=1, maximum=8, value=1, label=\"Upscale Factor\", step=1)\n",
        "            seed = gr.Number(label=\"Seed\", value=-1)\n",
        "            run = gr.Button(value=\"Run\")\n",
        "        with gr.Column():\n",
        "            result = gr.Image(type=\"pil\", format=\"png\")\n",
        "            status = gr.Textbox(label=\"status\", interactive=False)\n",
        "        run.click(\n",
        "            fn=process,\n",
        "            inputs=[image, prompt, upscale, seed],\n",
        "            outputs=[result, status],\n",
        "        )\n",
        "block.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "id": "ZeP7zvP_WeEY",
        "outputId": "593720c5-9b42-49d5-bfad-cdb5790e0641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max size set to (2048, 2048), max pixels: 4194304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load model weights from HYPIR_sd2.pth\n",
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://58899f87fcc429eb66.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://58899f87fcc429eb66.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}